\documentclass{article}
\usepackage[left=0.75in,top=0.65in,right=0.75in,bottom=0.55in]{geometry}

\begin{document}
\author{Ilya Verenich}
<<include=FALSE>>=
library(knitr)
opts_chunk$set(
concordance=TRUE
)
@

\title{Calculation of processing and overprocessing}
\date{}
\maketitle

\begin{equation}
\widetilde{W_\sigma}=
\sum_{i=1}^{N} ( P_i^r \cdot \prod_{k=1}^{i-1} (1 - P_k^r) \cdot (\sum_{j=1}^{i} E_j) )
\label{eq:estim-overproc}
\end{equation}

<<echo=FALSE, results='hide'>>=
library(ggplot2)
library(reshape)
 opts_knit$set(root.dir = "output/")
@

\section{For Bondora log}
<<echo=FALSE, results='hide'>>=
filenames <- list.files()[grep(paste("^output_Bondora(?=.*\\.csv)",sep=''), list.files(), perl=TRUE)]
dat = c()
result = matrix(0,nrow = length(filenames),ncol = 6)
colnames(result) = c("nr_checks_our","nr_checks_Wil","nr_checks_rand",
                     "overproc_our","overproc_Wil","overproc_rand")

for (i in 1:length(filenames)) {
  foo = read.table(filenames[i],sep=",",header=TRUE)
  dat = rbind(dat,foo)
  result[i,1] = mean(foo$nr_checks_our)
  result[i,2] = mean(foo$nr_checks_Wil)
  result[i,3] = mean(foo$nr_checks_rand)
  result[i,4] = mean(foo$nr_checks_our - foo$minimum_check_number)
  result[i,5] = mean(foo$nr_checks_Wil - foo$minimum_check_number)
  result[i,6] = mean(foo$nr_checks_rand - foo$minimum_check_number)
}
@

Minimal possible number of checks, averaged over \Sexpr{length(filenames)} test sets :

<<>>=
round(sum(dat$minimum_check_number)/length(filenames))
@


Average number of checks per test set that one would do if they follow \textbf{our ordering}:

<<>>=
round(sum(dat$nr_checks_our)/length(filenames))
@

Average number of checks that one would do if they apply \textbf{Wil's method} (constant reject probabilities):

<<>>=
round(sum(dat$nr_checks_Wil)/length(filenames))
@

Average number of checks that one would do if for every case they do checks in \textbf{random order}

<<>>=
round(sum(dat$nr_checks_rand)/length(filenames))
@

Average overprocessing (in \%) with our ordering:

<<>>=
round(100*(sum(dat$nr_checks_our) - sum(dat$minimum_check_number))/(length(filenames)*sum(dat$minimum_check_number)/length(filenames)),digits = 2)
@

Average overprocessing with Wil ordering:

<<>>=
round(100*(sum(dat$nr_checks_Wil) - sum(dat$minimum_check_number))/(length(filenames)*sum(dat$minimum_check_number)/length(filenames)),digits = 2)
@

Average overprocessing with random ordering:

<<>>=
round(100*(sum(dat$nr_checks_rand) - sum(dat$minimum_check_number))/(length(filenames)*sum(dat$minimum_check_number)/length(filenames)),digits = 2)
@

\textbf{Distribution of the number of checks performed}
<<echo=FALSE, results='hide'>>=
tt = matrix(0,nrow = 4,ncol = length(unique(dat$nr_checks_rand)))
rownames(tt) = c("count_checks_our","count_checks_Wil","count_checks_rand","minimal")
tt[1,] = round(table(dat$nr_checks_our)/length(filenames))
tt[2,] = round(table(dat$nr_checks_Wil)/length(filenames))
tt[3,] = round(table(dat$nr_checks_rand)/length(filenames))
tt[4,1] = round(sum(dat$minimum_check_number == 1)/length(filenames))
tt[4,2] = 0
tt[4,3] = round(sum(dat$minimum_check_number == 3)/length(filenames))
colnames(tt) = names(table(dat$nr_checks_rand))
@

<<>>=
print(tt)
@


\section{For Environmental permit log}
<<echo=FALSE, results='hide'>>=
filenames <- list.files()[grep(paste("^output_Envpermit(?=.*\\.csv)",sep=''), list.files(), perl=TRUE)]
dat = c()
result = matrix(0,nrow = length(filenames),ncol = 6)
colnames(result) = c("nr_checks_our","nr_checks_Wil","nr_checks_rand",
                     "overproc_our","overproc_Wil","overproc_rand")

for (i in 1:length(filenames)) {
  foo = read.table(filenames[i],sep=",",header=TRUE)
  dat = rbind(dat,foo)
  result[i,1] = mean(foo$nr_checks_our)
  result[i,2] = mean(foo$nr_checks_Wil)
  result[i,3] = mean(foo$nr_checks_rand)
  result[i,4] = mean(foo$nr_checks_our - foo$minimum_check_number)
  result[i,5] = mean(foo$nr_checks_Wil - foo$minimum_check_number)
  result[i,6] = mean(foo$nr_checks_rand - foo$minimum_check_number)
}
@

Minimal possible number of checks, averaged over \Sexpr{length(filenames)} test sets :

<<>>=
round(sum(dat$minimum_check_number)/length(filenames))
@


Average number of checks per test set that one would do if they follow \textbf{our ordering}:

<<>>=
round(sum(dat$nr_checks_our)/length(filenames))
@

Average number of checks that one would do if they apply \textbf{Wil's method} (constant reject probabilities):

<<>>=
round(sum(dat$nr_checks_Wil)/length(filenames))
@

Average number of checks that one would do if for every case they do checks in \textbf{random order}

<<>>=
round(sum(dat$nr_checks_rand)/length(filenames))
@

Average overprocessing (in \%) with our ordering:

<<>>=
round(100*(sum(dat$nr_checks_our) - sum(dat$minimum_check_number))/(length(filenames)*sum(dat$minimum_check_number)/length(filenames)),digits = 2)
@

Average overprocessing with Wil ordering:

<<>>=
round(100*(sum(dat$nr_checks_Wil) - sum(dat$minimum_check_number))/(length(filenames)*sum(dat$minimum_check_number)/length(filenames)),digits = 2)
@

Average overprocessing with random ordering:

<<>>=
round(100*(sum(dat$nr_checks_rand) - sum(dat$minimum_check_number))/(length(filenames)*sum(dat$minimum_check_number)/length(filenames)),digits = 2)
@

\textbf{Distribution of the number of checks performed}
<<echo=FALSE, results='hide'>>=
tt = matrix(0,nrow = 4,ncol = length(unique(dat$nr_checks_rand)))
rownames(tt) = c("count_checks_our","count_checks_Wil","count_checks_rand","minimal")
tt[1,] = round(table(dat$nr_checks_our)/length(filenames),digits = 1)
tt[2,] = round(table(dat$nr_checks_Wil)/length(filenames),digits = 1)
tt[3,] = round(table(dat$nr_checks_rand)/length(filenames),digits = 1)
tt[4,1] = sum(dat$minimum_check_number == 1)/length(filenames)
tt[4,2] = 0
tt[4,3] = sum(dat$minimum_check_number == 3)/length(filenames)
colnames(tt) = names(table(dat$nr_checks_rand))
@

<<>>=
print(tt)
@


\end{document}
